{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Star-galaxy Classification Using Deep Convolutonal Neural Networks\n",
    "\n",
    "This notebook demonstrates the Convolutional Neural Network used in the paper. Note that this notebook is for demonstration and testing purposes only. In the paper, we used a much larger training set of 50,000 images and a test set of 15,000 images.\n",
    "\n",
    "If you are using a GPU, uncomment the following code cell to write the Theano configuration file, `~/.theanorc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%writefile ~/.theanorc\\n[global]\\ndevice=gpu\\nfloatX=float32\\n\\n[blas]\\nldflags=-lopenblas\\n\\n[cuda]\\nroot=/opt/apps/cuda/7.0\\n\\n[nvcc]\\nfastmath=True\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%writefile ~/.theanorc\n",
    "[global]\n",
    "device=gpu\n",
    "floatX=float32\n",
    "\n",
    "[blas]\n",
    "ldflags=-lopenblas\n",
    "\n",
    "[cuda]\n",
    "root=/opt/apps/cuda/7.0\n",
    "\n",
    "[nvcc]\n",
    "fastmath=True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import categorical_crossentropy\n",
    "from lasagne.nonlinearities import leaky_rectify\n",
    "from lasagne.init import Orthogonal, Constant\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne.nonlinearities import softmax\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook uses only 100 training images. Run [fetch_sdss.py](https://github.com/EdwardJKim/dl4astro/blob/master/scripts/fetch_sdss.py) to create a larger training set. See also [fetch_sdss.ipynb](https://github.com/EdwardJKim/dl4astro/blob/master/notebooks/fetch_sdss.ipynb).\n",
    "\n",
    "The training set has already been shuffled, so we simply use the first 80 images to train and the remaining 20 images for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (100, 5, 48, 48), X.min = 16.8095626831, X.max = 25.861333847\n",
      "y.shape = (100,), y.min = -1.0, y.max = 1.0\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"../data/sdss_training_images.npy\")\n",
    "print(\"X.shape = {}, X.min = {}, X.max = {}\".format(X.shape, X.min(), X.max()))\n",
    "y = np.load(\"../data/sdss_training_labels.npy\")\n",
    "print(\"y.shape = {}, y.min = {}, y.max = {}\".format(y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (100, 5, 48, 48), X.min = 0.0, X.max = 1.0\n",
      "y.shape = (100,), y.min = 0, y.max = 1\n"
     ]
    }
   ],
   "source": [
    "def renormalize(array):\n",
    "    return (array - array.min()) / (array.max() - array.min())\n",
    "\n",
    "for i in range(5):\n",
    "    X[:, i, :, :] = renormalize(X[:, i, :, :])\n",
    "\n",
    "y = renormalize(y).astype(np.int32)\n",
    "print(\"X.shape = {}, X.min = {}, X.max = {}\".format(X.shape, X.min(), X.max()))\n",
    "print(\"y.shape = {}, y.min = {}, y.max = {}\".format(y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_PCA(array):\n",
    "\n",
    "    nimages0, nchannels0, height0, width0 = array.shape\n",
    "    rolled = np.transpose(array, (0, 2, 3, 1))\n",
    "    # transpose from N x channels x height x width  to  N x height x width x channels\n",
    "    nimages1, height1, width1, nchannels1 = rolled.shape\n",
    "    # check shapes\n",
    "    assert nimages0 == nimages1\n",
    "    assert nchannels0 == nchannels1\n",
    "    assert height0 == height1\n",
    "    assert width0 == width1\n",
    "    # flatten\n",
    "    reshaped = rolled.reshape(nimages1 * height1 * width1, nchannels1)\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(reshaped)\n",
    "\n",
    "    cov = pca.get_covariance()\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AugmentedBatchIterator(BatchIterator):\n",
    "\n",
    "    def __init__(self, batch_size, crop_size=8, testing=False):\n",
    "        super(AugmentedBatchIterator, self).__init__(batch_size)\n",
    "        self.crop_size = crop_size\n",
    "        self.testing = testing\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "\n",
    "        Xb, yb = super(AugmentedBatchIterator, self).transform(Xb, yb)\n",
    "        batch_size, nchannels, width, height = Xb.shape\n",
    "\n",
    "        if self.testing:\n",
    "            if self.crop_size % 2 == 0:\n",
    "                right = left = self.crop_size // 2\n",
    "            else:\n",
    "                right = self.crop_size // 2\n",
    "                left = self.crop_size // 2 + 1\n",
    "            X_new = Xb[:, :, right: -left, right: -left]\n",
    "            return X_new, yb\n",
    "\n",
    "        eigenvalues, eigenvectors = compute_PCA(Xb)\n",
    "\n",
    "        # Flip half of the images horizontally at random\n",
    "        indices = np.random.choice(batch_size, batch_size // 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "\n",
    "        # Crop images\n",
    "        X_new = np.zeros(\n",
    "            (batch_size, nchannels, width - self.crop_size, height - self.crop_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Choose x, y pixel posiitions at random\n",
    "            px, py = np.random.choice(self.crop_size, size=2)\n",
    "\n",
    "            sx = slice(px, px + width - self.crop_size)\n",
    "            sy = slice(py, py + height - self.crop_size)\n",
    "\n",
    "            # Rotate 0, 90, 180, or 270 degrees at random\n",
    "            nrotate = np.random.choice(4)\n",
    "\n",
    "            # add random color perturbation\n",
    "            alpha = np.random.normal(loc=0.0, scale=0.5, size=5)\n",
    "            noise = np.dot(eigenvectors, np.transpose(alpha * eigenvalues))\n",
    "\n",
    "            for j in range(nchannels):\n",
    "                X_new[i, j] = np.rot90(Xb[i, j, sx, sy] + noise[j], k=nrotate)\n",
    "\n",
    "        return X_new, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SaveParams(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if train_history[-1][\"valid_loss_best\"]:\n",
    "            nn.save_params_to(\"{}.params\".format(self.name))\n",
    "            with open(\"{}.history\".format(self.name), \"w\") as f:\n",
    "                pickle.dump(train_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UpdateLearningRate(object):\n",
    "\n",
    "    def __init__(self, start=0.001, stop=0.0001):\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = np.float32(self.ls[epoch - 1])\n",
    "        getattr(nn, \"update_learning_rate\").set_value(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainSplit(object):\n",
    "\n",
    "    def __init__(self, eval_size):\n",
    "        self.eval_size = eval_size\n",
    "\n",
    "    def __call__(self, X, y, net):\n",
    "        if self.eval_size:\n",
    "            X_train, y_train = X[:-self.eval_size], y[:-self.eval_size]\n",
    "            X_valid, y_valid = X[-self.eval_size:], y[-self.eval_size:]\n",
    "        else:\n",
    "            X_train, y_train = X, y\n",
    "            X_valid, y_valid = _sldict(X, slice(len(y), None)), y[len(y):]\n",
    "\n",
    "        return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "\n",
    "        ('conv11', layers.Conv2DLayer),\n",
    "        ('conv12', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('conv21', layers.Conv2DLayer),\n",
    "        ('conv22', layers.Conv2DLayer),\n",
    "        ('conv23', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('conv31', layers.Conv2DLayer),\n",
    "        ('conv32', layers.Conv2DLayer),\n",
    "        ('conv33', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "\n",
    "        ('dropout5', layers.DropoutLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 5, 44, 44),\n",
    "\n",
    "    conv11_num_filters=32, conv11_filter_size=(5, 5),\n",
    "    conv11_nonlinearity=leaky_rectify,\n",
    "    conv11_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv11_b=Constant(0.1),\n",
    "\n",
    "    conv12_num_filters=32, conv12_filter_size=(3, 3), conv12_pad=1,\n",
    "    conv12_nonlinearity=leaky_rectify,\n",
    "    conv12_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv12_b=Constant(0.1),\n",
    "\n",
    "    pool1_pool_size=(2, 2),\n",
    "\n",
    "    conv21_num_filters=64, conv21_filter_size=(3, 3), conv21_pad=1,\n",
    "    conv21_nonlinearity=leaky_rectify,\n",
    "    conv21_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv21_b=Constant(0.1),\n",
    "\n",
    "    conv22_num_filters=64, conv22_filter_size=(3, 3), conv22_pad=1,\n",
    "    conv22_nonlinearity=leaky_rectify,\n",
    "    conv22_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv22_b=Constant(0.1),\n",
    "    \n",
    "    conv23_num_filters=64, conv23_filter_size=(3, 3), conv23_pad=1,\n",
    "    conv23_nonlinearity=leaky_rectify,\n",
    "    conv23_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv23_b=Constant(0.1),\n",
    "\n",
    "    pool2_pool_size=(2, 2),\n",
    "\n",
    "    conv31_num_filters=128, conv31_filter_size=(3, 3), conv31_pad=1,\n",
    "    conv31_nonlinearity=leaky_rectify,\n",
    "    conv31_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv31_b=Constant(0.1),\n",
    "\n",
    "    conv32_num_filters=128, conv32_filter_size=(3, 3), conv32_pad=1,\n",
    "    conv32_nonlinearity=leaky_rectify,\n",
    "    conv32_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv32_b=Constant(0.1),\n",
    "\n",
    "    conv33_num_filters=128, conv33_filter_size=(3, 3), conv33_pad=1,\n",
    "    conv33_nonlinearity=leaky_rectify,\n",
    "    conv33_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), conv33_b=Constant(0.1),\n",
    "\n",
    "    pool3_pool_size=(2, 2),\n",
    "\n",
    "    hidden4_num_units=2048,\n",
    "    hidden4_nonlinearity=leaky_rectify,\n",
    "    hidden4_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), hidden4_b=Constant(0.01),\n",
    "    dropout4_p=0.5,\n",
    "\n",
    "    hidden5_num_units=2048,\n",
    "    hidden5_nonlinearity=leaky_rectify,\n",
    "    hidden5_W=Orthogonal(np.sqrt(2 / (1 + 0.01**2))), hidden5_b=Constant(0.01),\n",
    "    dropout5_p=0.5,\n",
    "\n",
    "    output_num_units=2,\n",
    "    output_nonlinearity=softmax,\n",
    "\n",
    "    update_learning_rate=theano.shared(np.float32(0.003)),\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    objective_loss_function=categorical_crossentropy,\n",
    "    regression=False,\n",
    "    max_epochs=100,\n",
    "    batch_iterator_train=AugmentedBatchIterator(batch_size=128, crop_size=4),\n",
    "    batch_iterator_test=AugmentedBatchIterator(batch_size=128, crop_size=4, testing=True),\n",
    "\n",
    "    on_epoch_finished=[\n",
    "        UpdateLearningRate(start=0.003, stop=0.0001),\n",
    "        SaveParams(\"net\")\n",
    "    ],\n",
    "\n",
    "    verbose=2,\n",
    "    train_split=TrainSplit(eval_size=20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 11230754 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name      size         total    cap.Y    cap.X    cov.Y    cov.X\n",
      "--------  ---------  -------  -------  -------  -------  -------\n",
      "input     5x44x44       9680   100.00   100.00   100.00   100.00\n",
      "conv11    32x40x40     51200   100.00   100.00    11.36    11.36\n",
      "conv12    32x40x40     51200    42.86    42.86    15.91    15.91\n",
      "pool1     32x20x20     12800    42.86    42.86    15.91    15.91\n",
      "conv21    64x20x20     25600    54.55    54.55    25.00    25.00\n",
      "conv22    64x20x20     25600    40.00    40.00    34.09    34.09\n",
      "conv23    64x20x20     25600    31.58    31.58    43.18    43.18\n",
      "pool2     64x10x10      6400    31.58    31.58    43.18    43.18\n",
      "conv31    128x10x10    12800    44.44    44.44    61.36    61.36\n",
      "conv32    128x10x10    12800    34.29    34.29    79.55    79.55\n",
      "conv33    128x10x10    12800    27.91    27.91    97.73    97.73\n",
      "pool3     128x5x5       3200    27.91    27.91    97.73    97.73\n",
      "dropout4  128x5x5       3200   100.00   100.00   100.00   100.00\n",
      "hidden4   2048          2048   100.00   100.00   100.00   100.00\n",
      "dropout5  2048          2048   100.00   100.00   100.00   100.00\n",
      "hidden5   2048          2048   100.00   100.00   100.00   100.00\n",
      "output    2                2   100.00   100.00   100.00   100.00\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m5.89239\u001b[0m      \u001b[32m20.87962\u001b[0m      0.28221      0.70000  2.04s\n",
      "      2      19.06602       \u001b[32m5.21316\u001b[0m      3.65728      0.70000  2.17s\n",
      "      3       \u001b[36m5.52811\u001b[0m       \u001b[32m3.00019\u001b[0m      1.84259      0.70000  2.01s\n",
      "      4       \u001b[36m3.25553\u001b[0m       \u001b[32m2.02346\u001b[0m      1.60889      0.70000  2.26s\n",
      "      5       \u001b[36m2.35769\u001b[0m       \u001b[32m1.54906\u001b[0m      1.52201      0.70000  1.97s\n",
      "      6       \u001b[36m1.88469\u001b[0m       \u001b[32m1.16222\u001b[0m      1.62163      0.70000  1.97s\n",
      "      7       \u001b[36m1.45267\u001b[0m       \u001b[32m0.85415\u001b[0m      1.70073      0.70000  1.97s\n",
      "      8       \u001b[36m0.99510\u001b[0m       \u001b[32m0.74516\u001b[0m      1.33542      0.70000  1.96s\n",
      "      9       \u001b[36m0.76525\u001b[0m       \u001b[32m0.68669\u001b[0m      1.11441      0.70000  2.24s\n",
      "     10       \u001b[36m0.62774\u001b[0m       \u001b[32m0.66606\u001b[0m      0.94246      0.70000  2.40s\n",
      "     11       \u001b[36m0.58699\u001b[0m       \u001b[32m0.65463\u001b[0m      0.89667      0.70000  2.47s\n",
      "     12       \u001b[36m0.57003\u001b[0m       \u001b[32m0.64921\u001b[0m      0.87805      0.70000  2.43s\n",
      "     13       \u001b[36m0.55892\u001b[0m       \u001b[32m0.64659\u001b[0m      0.86442      0.70000  2.53s\n",
      "     14       \u001b[36m0.54218\u001b[0m       \u001b[32m0.64638\u001b[0m      0.83879      0.70000  2.18s\n",
      "     15       0.55272       \u001b[32m0.64589\u001b[0m      0.85575      0.70000  2.22s\n",
      "     16       0.55431       \u001b[32m0.64548\u001b[0m      0.85875      0.70000  2.24s\n",
      "     17       0.54704       \u001b[32m0.64493\u001b[0m      0.84821      0.70000  2.08s\n",
      "     18       0.55461       \u001b[32m0.64349\u001b[0m      0.86187      0.70000  2.13s\n",
      "     19       0.55902       \u001b[32m0.64100\u001b[0m      0.87211      0.70000  2.07s\n",
      "     20       0.55920       \u001b[32m0.63782\u001b[0m      0.87674      0.70000  2.12s\n",
      "     21       0.55821       \u001b[32m0.63420\u001b[0m      0.88017      0.70000  2.16s\n",
      "     22       0.55541       \u001b[32m0.63045\u001b[0m      0.88097      0.70000  2.16s\n",
      "     23       0.55589       \u001b[32m0.62668\u001b[0m      0.88704      0.70000  2.13s\n",
      "     24       0.54373       \u001b[32m0.62331\u001b[0m      0.87233      0.70000  2.26s\n",
      "     25       0.54356       \u001b[32m0.62021\u001b[0m      0.87641      0.70000  2.25s\n",
      "     26       \u001b[36m0.53694\u001b[0m       \u001b[32m0.61757\u001b[0m      0.86944      0.70000  2.21s\n",
      "     27       0.53947       \u001b[32m0.61536\u001b[0m      0.87668      0.70000  2.09s\n",
      "     28       \u001b[36m0.52640\u001b[0m       \u001b[32m0.61365\u001b[0m      0.85783      0.70000  2.18s\n",
      "     29       0.52839       \u001b[32m0.61242\u001b[0m      0.86279      0.70000  2.08s\n",
      "     30       \u001b[36m0.52555\u001b[0m       \u001b[32m0.61162\u001b[0m      0.85927      0.70000  1.96s\n",
      "     31       0.52602       \u001b[32m0.61123\u001b[0m      0.86059      0.70000  2.03s\n",
      "     32       \u001b[36m0.52286\u001b[0m       \u001b[32m0.61118\u001b[0m      0.85549      0.70000  2.19s\n",
      "     33       \u001b[36m0.51871\u001b[0m       0.61137      0.84843      0.70000  2.06s\n",
      "     34       0.52105       0.61192      0.85150      0.70000  1.86s\n",
      "     35       \u001b[36m0.51511\u001b[0m       0.61264      0.84081      0.70000  1.87s\n",
      "     36       0.51908       0.61336      0.84629      0.70000  1.86s\n",
      "     37       \u001b[36m0.51425\u001b[0m       0.61414      0.83734      0.70000  1.86s\n",
      "     38       0.51842       0.61492      0.84307      0.70000  1.86s\n",
      "     39       0.51995       0.61575      0.84443      0.70000  1.95s\n",
      "     40       0.51537       0.61654      0.83590      0.70000  2.03s\n",
      "     41       0.51682       0.61726      0.83727      0.70000  1.98s\n",
      "     42       0.52181       0.61798      0.84439      0.70000  2.02s\n",
      "     43       0.51993       0.61870      0.84036      0.70000  2.00s\n",
      "     44       0.51965       0.61950      0.83882      0.70000  2.04s\n",
      "     45       0.51943       0.62005      0.83771      0.70000  2.08s\n",
      "     46       0.52223       0.62057      0.84154      0.70000  2.08s\n",
      "     47       0.51820       0.62104      0.83440      0.70000  2.07s\n",
      "     48       0.51666       0.62119      0.83172      0.70000  2.09s\n",
      "     49       0.51726       0.62003      0.83424      0.70000  2.10s\n",
      "     50       0.52038       0.61959      0.83988      0.70000  2.08s\n",
      "     51       0.51826       0.61916      0.83704      0.70000  2.05s\n",
      "     52       \u001b[36m0.51202\u001b[0m       0.61692      0.82996      0.70000  2.08s\n",
      "     53       0.51762       0.61654      0.83956      0.70000  2.07s\n",
      "     54       0.52616       0.61888      0.85019      0.70000  2.07s\n",
      "     55       0.51996       0.62063      0.83780      0.70000  2.07s\n",
      "     56       0.51669       0.62085      0.83223      0.70000  2.09s\n",
      "     57       0.51983       0.62127      0.83672      0.70000  2.07s\n",
      "     58       0.51634       0.62130      0.83106      0.70000  2.07s\n",
      "     59       0.51999       0.62119      0.83708      0.70000  2.09s\n",
      "     60       0.51897       0.62115      0.83550      0.70000  2.06s\n",
      "     61       0.51394       0.62114      0.82741      0.70000  2.06s\n",
      "     62       0.51430       0.62051      0.82884      0.70000  2.05s\n",
      "     63       0.51684       0.61994      0.83369      0.70000  2.07s\n",
      "     64       0.51236       0.61922      0.82743      0.70000  2.08s\n",
      "     65       0.51717       0.61804      0.83678      0.70000  2.12s\n",
      "     66       0.52618       0.61836      0.85092      0.70000  2.06s\n",
      "     67       0.51550       0.61867      0.83324      0.70000  2.09s\n",
      "     68       0.51556       0.61850      0.83357      0.70000  2.12s\n",
      "     69       0.51539       0.61881      0.83288      0.70000  2.07s\n",
      "     70       0.52002       0.61896      0.84015      0.70000  2.01s\n",
      "     71       \u001b[36m0.50939\u001b[0m       0.61809      0.82414      0.70000  2.07s\n",
      "     72       0.51347       0.61778      0.83115      0.70000  2.05s\n",
      "     73       0.51236       0.61735      0.82992      0.70000  2.07s\n",
      "     74       0.52552       0.61746      0.85111      0.70000  2.06s\n",
      "     75       0.51450       0.61685      0.83407      0.70000  2.06s\n",
      "     76       0.51858       0.61694      0.84057      0.70000  2.04s\n",
      "     77       0.51707       0.61738      0.83752      0.70000  2.03s\n",
      "     78       0.51817       0.61841      0.83790      0.70000  1.98s\n",
      "     79       \u001b[36m0.50843\u001b[0m       0.61816      0.82249      0.70000  2.06s\n",
      "     80       0.51200       0.61822      0.82818      0.70000  2.03s\n",
      "     81       0.51464       0.61843      0.83217      0.70000  2.04s\n",
      "     82       0.51661       0.61821      0.83566      0.70000  2.05s\n",
      "     83       0.51868       0.61854      0.83857      0.70000  2.07s\n",
      "     84       0.52019       0.61879      0.84067      0.70000  2.06s\n",
      "     85       0.51743       0.61905      0.83585      0.70000  2.06s\n",
      "     86       0.52548       0.62011      0.84739      0.70000  1.99s\n",
      "     87       0.52281       0.62111      0.84173      0.70000  2.01s\n",
      "     88       0.52350       0.62173      0.84200      0.70000  1.86s\n",
      "     89       0.51619       0.62230      0.82949      0.70000  1.86s\n",
      "     90       0.51178       0.62241      0.82227      0.70000  1.86s\n",
      "     91       0.51792       0.62254      0.83195      0.70000  1.86s\n",
      "     92       0.52013       0.62268      0.83530      0.70000  1.86s\n",
      "     93       0.51229       0.62263      0.82279      0.70000  1.86s\n",
      "     94       0.51770       0.62253      0.83161      0.70000  1.86s\n",
      "     95       0.51611       0.62229      0.82937      0.70000  1.86s\n",
      "     96       0.51573       0.62207      0.82905      0.70000  1.86s\n",
      "     97       0.51418       0.62184      0.82688      0.70000  1.86s\n",
      "     98       0.51470       0.62152      0.82813      0.70000  1.86s\n",
      "     99       0.51857       0.62124      0.83473      0.70000  1.86s\n",
      "    100       0.51308       0.62097      0.82626      0.70000  1.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<__main__.AugmentedBatchIterator object at 0x7fdf2435ca50>,\n",
       "     batch_iterator_train=<__main__.AugmentedBatchIterator object at 0x7fdf24404710>,\n",
       "     check_input=True,\n",
       "     conv11_W=<lasagne.init.Orthogonal object at 0x7fdf24404210>,\n",
       "     conv11_b=<lasagne.init.Constant object at 0x7fdf24404250>,\n",
       "     conv11_filter_size=(5, 5),\n",
       "     conv11_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv11_num_filters=32,\n",
       "     conv12_W=<lasagne.init.Orthogonal object at 0x7fdf24404290>,\n",
       "     conv12_b=<lasagne.init.Constant object at 0x7fdf244042d0>,\n",
       "     conv12_filter_size=(3, 3),\n",
       "     conv12_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv12_num_filters=32, conv12_pad=1,\n",
       "     conv21_W=<lasagne.init.Orthogonal object at 0x7fdf24404310>,\n",
       "     conv21_b=<lasagne.init.Constant object at 0x7fdf24404350>,\n",
       "     conv21_filter_size=(3, 3),\n",
       "     conv21_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv21_num_filters=64, conv21_pad=1,\n",
       "     conv22_W=<lasagne.init.Orthogonal object at 0x7fdf24404390>,\n",
       "     conv22_b=<lasagne.init.Constant object at 0x7fdf244043d0>,\n",
       "     conv22_filter_size=(3, 3),\n",
       "     conv22_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv22_num_filters=64, conv22_pad=1,\n",
       "     conv23_W=<lasagne.init.Orthogonal object at 0x7fdf24404410>,\n",
       "     conv23_b=<lasagne.init.Constant object at 0x7fdf24404450>,\n",
       "     conv23_filter_size=(3, 3),\n",
       "     conv23_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv23_num_filters=64, conv23_pad=1,\n",
       "     conv31_W=<lasagne.init.Orthogonal object at 0x7fdf24404490>,\n",
       "     conv31_b=<lasagne.init.Constant object at 0x7fdf244044d0>,\n",
       "     conv31_filter_size=(3, 3),\n",
       "     conv31_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv31_num_filters=128, conv31_pad=1,\n",
       "     conv32_W=<lasagne.init.Orthogonal object at 0x7fdf24404510>,\n",
       "     conv32_b=<lasagne.init.Constant object at 0x7fdf24404550>,\n",
       "     conv32_filter_size=(3, 3),\n",
       "     conv32_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv32_num_filters=128, conv32_pad=1,\n",
       "     conv33_W=<lasagne.init.Orthogonal object at 0x7fdf24404590>,\n",
       "     conv33_b=<lasagne.init.Constant object at 0x7fdf244045d0>,\n",
       "     conv33_filter_size=(3, 3),\n",
       "     conv33_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     conv33_num_filters=128, conv33_pad=1, custom_scores=None,\n",
       "     dropout4_p=0.5, dropout5_p=0.5,\n",
       "     hidden4_W=<lasagne.init.Orthogonal object at 0x7fdf24404610>,\n",
       "     hidden4_b=<lasagne.init.Constant object at 0x7fdf24404650>,\n",
       "     hidden4_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     hidden4_num_units=2048,\n",
       "     hidden5_W=<lasagne.init.Orthogonal object at 0x7fdf24404690>,\n",
       "     hidden5_b=<lasagne.init.Constant object at 0x7fdf244046d0>,\n",
       "     hidden5_nonlinearity=<lasagne.nonlinearities.LeakyRectify object at 0x7fdf261a6410>,\n",
       "     hidden5_num_units=2048, input_shape=(None, 5, 44, 44),\n",
       "     layers=[(u'input', <class 'lasagne.layers.input.InputLayer'>), (u'conv11', <class 'lasagne.layers.conv.Conv2DLayer'>), (u'conv12', <class 'lasagne.layers.conv.Conv2DLayer'>), (u'pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), (u'conv21', <class 'lasagne.layers.conv.Conv2DLayer'>), (u'conv22',... <class 'lasagne.layers.dense.DenseLayer'>), (u'output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x7fdf24946aa0>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7fdf26024050>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<__main__.UpdateLearningRate object at 0x7fdf2435cad0>, <__main__.SaveParams object at 0x7fdf2435cb10>, <nolearn.lasagne.handlers.PrintLog instance at 0x7fdf243ede60>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7fdf24362cb0>],\n",
       "     output_nonlinearity=<function softmax at 0x7fdf261a5c80>,\n",
       "     output_num_units=2, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),\n",
       "     pool3_pool_size=(2, 2), regression=False,\n",
       "     train_split=<__main__.TrainSplit object at 0x7fdf2435cb50>,\n",
       "     update=<function nesterov_momentum at 0x7fdf26024cf8>,\n",
       "     update_learning_rate=<TensorType(float32, scalar)>,\n",
       "     update_momentum=0.9, use_label_encoder=False, verbose=2,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid loss: 0.611180422227\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = min([row['valid_loss'] for row in net.train_history_])\n",
    "print(\"Best valid loss: {}\".format(best_valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid = X[-20:]\n",
    "y_valid = y[-20:]\n",
    "\n",
    "for i in range(5):\n",
    "    X_valid[:, i, :, :] = renormalize(X_valid[:, i, :, :])\n",
    "\n",
    "y_valid = renormalize(y_valid).astype(np.int32)\n",
    "\n",
    "y_pred_valid = np.zeros((len(y_valid), 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AugmentedBatchIterator(BatchIterator):\n",
    "\n",
    "    def __init__(self, batch_size, crop_size=8, validation=False, testing=False, startx=None, starty=None, rotate=None):\n",
    "        super(AugmentedBatchIterator, self).__init__(batch_size)\n",
    "        self.crop_size = crop_size\n",
    "        self.validation = validation\n",
    "        self.testing = testing\n",
    "        self.startx, self.starty = startx, starty\n",
    "        self.rotate = rotate\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "\n",
    "        Xb, yb = super(AugmentedBatchIterator, self).transform(Xb, yb)\n",
    "        batch_size, nchannels, width, height = Xb.shape\n",
    "\n",
    "        if self.validation:\n",
    "            if self.crop_size % 2 == 0:\n",
    "                right = left = self.crop_size // 2\n",
    "            else:\n",
    "                right = self.crop_size // 2\n",
    "                left = self.crop_size // 2 + 1\n",
    "            X_new = Xb[:, :, right: -left, right: -left]\n",
    "            return X_new, yb\n",
    "\n",
    "        if not self.testing:\n",
    "            eigenvalues, eigenvectors = compute_PCA(Xb)\n",
    "\n",
    "        # Flip half of the images horizontally at random\n",
    "        indices = np.random.choice(batch_size, batch_size // 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "\n",
    "        # Crop images\n",
    "        X_new = np.zeros(\n",
    "            (batch_size, nchannels, width - self.crop_size, height - self.crop_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if self.testing:\n",
    "                px, py = self.startx, self.starty\n",
    "            else:\n",
    "                # Choose x, y pixel posiitions at random\n",
    "                px, py = np.random.choice(self.crop_size, size=2)\n",
    "\n",
    "            sx = slice(px, px + width - self.crop_size)\n",
    "            sy = slice(py, py + height - self.crop_size)\n",
    "\n",
    "            # Rotate 0, 90, 180, or 270 degrees at random\n",
    "            if self.testing:\n",
    "                nrotate = self.rotate\n",
    "                noise = np.zeros(nchannels)\n",
    "            else:\n",
    "                nrotate = np.random.choice(4)\n",
    "                # add random color perturbation\n",
    "                alpha = np.random.normal(loc=0.0, scale=0.5, size=5)\n",
    "                noise = np.dot(eigenvectors, np.transpose(alpha * eigenvalues))\n",
    "\n",
    "            for j in range(nchannels):\n",
    "                X_new[i, j] = np.rot90(Xb[i, j, sx, sy] + noise[j], k=nrotate)\n",
    "\n",
    "        return X_new, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model combination...\n",
      "Iteration: 1 / 64\n",
      "Iteration: 2 / 64\n",
      "Iteration: 3 / 64\n",
      "Iteration: 4 / 64\n",
      "Iteration: 5 / 64\n",
      "Iteration: 6 / 64\n",
      "Iteration: 7 / 64\n",
      "Iteration: 8 / 64\n",
      "Iteration: 9 / 64\n",
      "Iteration: 10 / 64\n",
      "Iteration: 11 / 64\n",
      "Iteration: 12 / 64\n",
      "Iteration: 13 / 64\n",
      "Iteration: 14 / 64\n",
      "Iteration: 15 / 64\n",
      "Iteration: 16 / 64\n",
      "Iteration: 17 / 64\n",
      "Iteration: 18 / 64\n",
      "Iteration: 19 / 64\n",
      "Iteration: 20 / 64\n",
      "Iteration: 21 / 64\n",
      "Iteration: 22 / 64\n",
      "Iteration: 23 / 64\n",
      "Iteration: 24 / 64\n",
      "Iteration: 25 / 64\n",
      "Iteration: 26 / 64\n",
      "Iteration: 27 / 64\n",
      "Iteration: 28 / 64\n",
      "Iteration: 29 / 64\n",
      "Iteration: 30 / 64\n",
      "Iteration: 31 / 64\n",
      "Iteration: 32 / 64\n",
      "Iteration: 33 / 64\n",
      "Iteration: 34 / 64\n",
      "Iteration: 35 / 64\n",
      "Iteration: 36 / 64\n",
      "Iteration: 37 / 64\n",
      "Iteration: 38 / 64\n",
      "Iteration: 39 / 64\n",
      "Iteration: 40 / 64\n",
      "Iteration: 41 / 64\n",
      "Iteration: 42 / 64\n",
      "Iteration: 43 / 64\n",
      "Iteration: 44 / 64\n",
      "Iteration: 45 / 64\n",
      "Iteration: 46 / 64\n",
      "Iteration: 47 / 64\n",
      "Iteration: 48 / 64\n",
      "Iteration: 49 / 64\n",
      "Iteration: 50 / 64\n",
      "Iteration: 51 / 64\n",
      "Iteration: 52 / 64\n",
      "Iteration: 53 / 64\n",
      "Iteration: 54 / 64\n",
      "Iteration: 55 / 64\n",
      "Iteration: 56 / 64\n",
      "Iteration: 57 / 64\n",
      "Iteration: 58 / 64\n",
      "Iteration: 59 / 64\n",
      "Iteration: 60 / 64\n",
      "Iteration: 61 / 64\n",
      "Iteration: 62 / 64\n",
      "Iteration: 63 / 64\n",
      "Iteration: 64 / 64\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "print(\"Starting model combination...\")\n",
    "\n",
    "for startx in range(4):\n",
    "    for starty in range(4):\n",
    "        for rotate in range(4):\n",
    "\n",
    "            net.batch_iterator_test=AugmentedBatchIterator(\n",
    "                batch_size=128,\n",
    "                crop_size=4,\n",
    "                testing=True,\n",
    "                startx=startx,\n",
    "                starty=starty,\n",
    "                rotate=rotate\n",
    "            )\n",
    "            y_pred_valid[:, count] = net.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            print(\"Iteration: {} / 64\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.bmc import BMC\n",
    "bmc = BMC()\n",
    "bmc.fit(y_pred_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape = (20, 5, 48, 48), X_test.min = 0.0, X_test.max = 1.0\n",
      "y_test.shape = (20,), y_test.min = 0, y_test.max = 1\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"../data/sdss_test_images.npy\")\n",
    "y_test = np.load(\"../data/sdss_test_labels.npy\")\n",
    "\n",
    "for i in range(5):\n",
    "    X_test[:, i, :, :] = renormalize(X_test[:, i, :, :])\n",
    "\n",
    "y_test = renormalize(y_test).astype(np.int32)\n",
    "\n",
    "print(\"X_test.shape = {}, X_test.min = {}, X_test.max = {}\".format(\n",
    "    X_test.shape, X_test.min(), X_test.max()\n",
    "    ))\n",
    "print(\"y_test.shape = {}, y_test.min = {}, y_test.max = {}\".format(\n",
    "    y_test.shape, y_test.min(), y_test.max()\n",
    "    ))\n",
    "\n",
    "y_pred_test = np.zeros((len(y_test), 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 / 64\n",
      "Iteration: 2 / 64\n",
      "Iteration: 3 / 64\n",
      "Iteration: 4 / 64\n",
      "Iteration: 5 / 64\n",
      "Iteration: 6 / 64\n",
      "Iteration: 7 / 64\n",
      "Iteration: 8 / 64\n",
      "Iteration: 9 / 64\n",
      "Iteration: 10 / 64\n",
      "Iteration: 11 / 64\n",
      "Iteration: 12 / 64\n",
      "Iteration: 13 / 64\n",
      "Iteration: 14 / 64\n",
      "Iteration: 15 / 64\n",
      "Iteration: 16 / 64\n",
      "Iteration: 17 / 64\n",
      "Iteration: 18 / 64\n",
      "Iteration: 19 / 64\n",
      "Iteration: 20 / 64\n",
      "Iteration: 21 / 64\n",
      "Iteration: 22 / 64\n",
      "Iteration: 23 / 64\n",
      "Iteration: 24 / 64\n",
      "Iteration: 25 / 64\n",
      "Iteration: 26 / 64\n",
      "Iteration: 27 / 64\n",
      "Iteration: 28 / 64\n",
      "Iteration: 29 / 64\n",
      "Iteration: 30 / 64\n",
      "Iteration: 31 / 64\n",
      "Iteration: 32 / 64\n",
      "Iteration: 33 / 64\n",
      "Iteration: 34 / 64\n",
      "Iteration: 35 / 64\n",
      "Iteration: 36 / 64\n",
      "Iteration: 37 / 64\n",
      "Iteration: 38 / 64\n",
      "Iteration: 39 / 64\n",
      "Iteration: 40 / 64\n",
      "Iteration: 41 / 64\n",
      "Iteration: 42 / 64\n",
      "Iteration: 43 / 64\n",
      "Iteration: 44 / 64\n",
      "Iteration: 45 / 64\n",
      "Iteration: 46 / 64\n",
      "Iteration: 47 / 64\n",
      "Iteration: 48 / 64\n",
      "Iteration: 49 / 64\n",
      "Iteration: 50 / 64\n",
      "Iteration: 51 / 64\n",
      "Iteration: 52 / 64\n",
      "Iteration: 53 / 64\n",
      "Iteration: 54 / 64\n",
      "Iteration: 55 / 64\n",
      "Iteration: 56 / 64\n",
      "Iteration: 57 / 64\n",
      "Iteration: 58 / 64\n",
      "Iteration: 59 / 64\n",
      "Iteration: 60 / 64\n",
      "Iteration: 61 / 64\n",
      "Iteration: 62 / 64\n",
      "Iteration: 63 / 64\n",
      "Iteration: 64 / 64\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for startx in range(4):\n",
    "    for starty in range(4):\n",
    "        for rotate in range(4):\n",
    "\n",
    "            net.batch_iterator_test=AugmentedBatchIterator(\n",
    "                batch_size=128,\n",
    "                crop_size=4,\n",
    "                testing=True,\n",
    "                startx=startx,\n",
    "                starty=starty,\n",
    "                rotate=rotate\n",
    "            )\n",
    "            y_pred_test[:, count] = net.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            print(\"Iteration: {} / 64\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bmc.predict_proba(y_pred_test)\n",
    "np.save(\"sdss_convnet_pred.npy\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Area under the ROC curve: {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
